{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preparation import process_caption_index_helper, invoke_emotion_to_dataset, invoke_edited_to_dataset, load_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "mongo_dump_path = './dataset/dump/041619.json'\n",
    "path = './dataset/caption_bc.json'\n",
    "flickr_folder = './dataset/flickr10k'\n",
    "coco_folder = './dataset/mscoco'\n",
    "save_path = './dataset/cache/caption_index.helper'\n",
    "image_id_to_idx = process_caption_index_helper(path, flickr_folder, coco_folder, save_path)\n",
    "for mode in ['happy', 'sad', 'angry']:\n",
    "    invoke_emotion_to_dataset(mongo_dump_path,image_id_to_idx, flickr_folder, 'flickr', mode)\n",
    "invoke_edited_to_dataset(mongo_dump_path, flickr_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"_id\":{\"$oid\":\"5c1fa377260e573d840dbbca\"},\"captions\":[{\"id\":\"Seorang lelaki mengenakan celana pendek dan kemeja Hawaii bersandar di atas rel perahu pilot, dengan kabut dan pegunungan di latar belakang.\",\"en\":\"A man in shorts and a Hawaiian shirt leans over the rail of a pilot boat , with fog and mountains in the background .\",\"caption_id\":464109},{\"id\":\"Seorang pria muda yang tergantung di sisi perahu, yang dalam kondisi seperti kabut berguling di atas bukit di belakangnya.\",\"en\":\"A young man hanging over the side of a boat , which is in a like with fog rolling over a hill behind it .\",\"caption_id\":464110},{\"id\":\"Seorang pria bersandar di sisi perahu biru dan putih saat ia duduk di badan air.\",\"en\":\"A man is leaning off of the side of a blue and white boat as it sits in a body of water .\",\"caption_id\":464111},{\"id\":\"Seorang pria menaiki perahu kecil di pelabuhan, dengan kabut dan pegunungan di latar belakang.\",\"en\":\"A man riding a small boat in a harbor , with fog and mountains in the background .\",\"caption_id\":464112},{\"id\":\"Seorang lelaki di atas perahu biru dan putih yang ditambatkan dengan bukit-bukit dan kabut di latar belakang.\",\"en\":\"A man on a moored blue and white boat with hills and mist in the background .\",\"caption_id\":464113}],\"file_name\":\"998845445.jpg\",\"image_id\":\"flickr-998845445\",\"url\":\"https://geekstudio.id/dataset/flickr30k/images/998845445.jpg\",\"obj_id\":92783,\"need_emotion\":true}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        print(l)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset/flickr10k/test.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-79e7172ccfc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_caption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflickr_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'edited'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/final_project/13515097-stylenet/preparation.py\u001b[0m in \u001b[0;36mload_caption\u001b[0;34m(path_folder, lang, modes)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/val.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mvalidation_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/test.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mtest_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/flickr10k/test.txt'"
     ]
    }
   ],
   "source": [
    "train, val = load_caption(flickr_folder, lang='edited')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_train, captions_train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_train['sad'][99:104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames_train['sad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '5588403950.jpg'\n",
    "for filename, caption in zip(filenames_train['happy'], captions_train['happy']):\n",
    "    if filename == target:\n",
    "        print(caption)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, caption in zip(filenames_train['angry'], captions_train['angry']):\n",
    "    if filename == target:\n",
    "        print(caption)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preparation import convert_mongo, split_and_save, load_caption\n",
    "\n",
    "path = './dataset'\n",
    "flickr_folder = path + '/flickr10k'\n",
    "coco_folder = path + '/mscoco'\n",
    "\n",
    "# # convert mongo to caption dict\n",
    "# caption_flickr, caption_coco = convert_mongo(path=path + '/caption_bc.json')\n",
    "\n",
    "# # save\n",
    "# with open(flickr_folder + '/caption.json', 'w') as f:\n",
    "#     json.dump(caption_flickr, f)\n",
    "# with open(coco_folder + '/caption.json', 'w') as f:\n",
    "#     json.dump(caption_coco, f)\n",
    "\n",
    "# split_and_save(caption_flickr, flickr_folder)\n",
    "# split_and_save(caption_coco, coco_folder)\n",
    "\n",
    "train, val = load_caption(flickr_folder)\n",
    "filenames_train, captions_train = train\n",
    "filenames_val, captions_val = val\n",
    "num_images_train = len(filenames_train['factual'])\n",
    "num_images_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for caption in zip(filenames_train, captions_train):\n",
    "    print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tokenizer import mark_captions, flatten, TokenizerWrap, mark_start, mark_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.52 s, sys: 20.5 ms, total: 2.54 s\n",
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_words = 10000\n",
    "modes = ['happy', 'sad', 'angry']\n",
    "captions_train_flat_all = []\n",
    "for mode in ['factual']:\n",
    "    captions_train_marked = mark_captions(captions_train[mode])\n",
    "    captions_train_flat = flatten(captions_train_marked)\n",
    "    tokenizer = TokenizerWrap(texts=captions_train_flat, num_words=num_words)\n",
    "    # remove oov words\n",
    "    tmp = tokenizer.texts_to_sequences(captions_train_flat)\n",
    "    captions_train_flat = tokenizer.sequences_to_texts(tmp)\n",
    "    captions_train_flat_all.extend(captions_train_flat)\n",
    "tokenizer = TokenizerWrap(texts=captions_train_flat_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 800 ms, sys: 10.6 ms, total: 810 ms\n",
      "Wall time: 813 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "captions_train_marked = mark_captions(captions_train['factual'])\n",
    "captions_train_flat = flatten(captions_train_marked)\n",
    "tokens_train = tokenizer.captions_to_tokens(captions_train_marked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mencoleknya'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_to_word[last]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = ['it is a gloomy day', 'it is a sunny day village']\n",
    "hypotesis = 'it is a great day'\n",
    "references = [reference.split(' ') for reference in references]\n",
    "hypotesis = hypotesis.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dery/Documents/final_project/13515097-stylenet/env/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51.43157015215767"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu(references, hypotesis, weights=(0.33, 0.33, 0.33, 0))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_filenames = filenames_train['factual']\n",
    "all_captions = captions_train_marked\n",
    "len(all_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using heuristic to sort captions from the largest word frequency\n",
    "\n",
    "pair_all_captions = []\n",
    "for i in range(len(all_filenames)):\n",
    "    caps = all_captions[i]\n",
    "    filenames = all_filenames[i]\n",
    "    total = 0\n",
    "    length = 0\n",
    "    for cap in tokenizer.texts_to_sequences(caps):\n",
    "        for word_i in cap:\n",
    "            length += 1\n",
    "            word = tokenizer.index_to_word[word_i]\n",
    "            total += tokenizer.word_counts[word]\n",
    "    pair_all_captions.append((total/length, i))\n",
    "pair_all_captions = sorted(pair_all_captions, key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_num = len(all_filenames) * 1 // 10\n",
    "test_num = len(all_filenames) * 1 // 10\n",
    "train_indexes = []\n",
    "val_indexes = []\n",
    "test_indexes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all proper indexes for train, val, and test\n",
    "# Train must have all words within dataset\n",
    "\n",
    "word_counts = tokenizer.word_counts\n",
    "\n",
    "for total, index in pair_all_captions:\n",
    "    caps = all_captions[index]\n",
    "    is_safe = True\n",
    "    for cap in tokenizer.texts_to_sequences(caps):\n",
    "        if not is_safe:\n",
    "            break\n",
    "        for word_i in cap:\n",
    "            if not is_safe:\n",
    "                break\n",
    "            word = tokenizer.index_to_word[word_i]\n",
    "            cnt = word_counts[word]\n",
    "            word_counts[word] -= 1\n",
    "            is_safe = cnt>1\n",
    "    if is_safe and len(val_indexes)<val_num:\n",
    "        val_indexes.append(index)\n",
    "    elif is_safe and len(test_indexes)<test_num:\n",
    "        test_indexes.append(index)\n",
    "    else:\n",
    "        train_indexes.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for i in train_indexes:\n",
    "    caps = all_captions[i]\n",
    "    for cap in tokenizer.texts_to_sequences(caps):\n",
    "        all_words.extend(cap)\n",
    "for i in val_indexes:\n",
    "    caps = all_captions[i]\n",
    "    for cap in tokenizer.texts_to_sequences(caps):\n",
    "        all_words.extend(cap)\n",
    "for i in test_indexes:\n",
    "    caps = all_captions[i]\n",
    "    for cap in tokenizer.texts_to_sequences(caps):\n",
    "        all_words.extend(cap)\n",
    "all_words = list(set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9630"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9630"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from preparation import convert_mongo\n",
    "import json\n",
    "\n",
    "mongo_dump_path = './dataset/dump/041619.json'\n",
    "path = './dataset/caption_bc.json'\n",
    "flickr_folder = './dataset/flickr10k'\n",
    "coco_folder = './dataset/mscoco'\n",
    "save_path = './dataset/cache/caption_index.helper'\n",
    "caption_flickr, caption_coco = convert_mongo(path)\n",
    "\n",
    "with open(flickr_folder + '/captions.json', 'r') as f:\n",
    "    caption_flickr = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preparation import invoke_emotion_to_dataset, invoke_edited_to_dataset, load_caption\n",
    "\n",
    "for mode in ['happy', 'sad', 'angry']:\n",
    "    invoke_emotion_to_dataset(mongo_dump_path, flickr_folder, 'flickr', mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filenames = {\n",
    "    'factual': [],\n",
    "    'happy': [],\n",
    "    'sad': [],\n",
    "    'angry': []\n",
    "}\n",
    "all_captions = {\n",
    "    'factual': [],\n",
    "    'happy': [],\n",
    "    'sad': [],\n",
    "    'angry': []\n",
    "}\n",
    "for mode in ['happy', 'sad', 'angry']:\n",
    "    for data in caption_flickr:\n",
    "        if data['emotions'].get(mode):\n",
    "            all_filenames[mode].append(data['filename'])\n",
    "            all_captions[mode].append([data['emotions'][mode]])\n",
    "all_filenames['factual'] = [data['filename'] for data in caption_flickr]\n",
    "all_captions['factual'] = [[caption['id'] for caption in data['captions']] for data in caption_flickr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import mark_captions, flatten, TokenizerWrap, mark_start, mark_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.99 s, sys: 29.5 ms, total: 3.02 s\n",
      "Wall time: 3.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modes = ['happy', 'sad', 'angry']\n",
    "captions_flat_all = []\n",
    "for mode in ['factual'] + modes:\n",
    "    captions_marked = mark_captions(all_captions[mode])\n",
    "    captions_flat = flatten(captions_marked)\n",
    "    tokenizer = TokenizerWrap(texts=captions_flat)\n",
    "    # remove oov words\n",
    "    tmp = tokenizer.texts_to_sequences(captions_flat)\n",
    "    captions_flat = tokenizer.sequences_to_texts(tmp)\n",
    "    captions_flat_all.extend(captions_flat)\n",
    "tokenizer = TokenizerWrap(texts=captions_flat_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preparation import split_dataset, save_dataset\n",
    "\n",
    "modes = ['happy', 'sad', 'angry']\n",
    "for mode in ['factual'] + modes:\n",
    "    train_indexes, val_indexes, test_indexes = split_dataset(all_filenames[mode], all_captions[mode], flickr_folder + '/' + mode, tokenizer, 10, 10)\n",
    "    save_dataset(all_filenames[mode], all_captions[mode], flickr_folder + '/' + mode, train_indexes, val_indexes, test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preparation import load_caption\n",
    "\n",
    "train, val, test = load_caption(flickr_folder + '/angry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
